\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[letterpaper,margin=1in]{geometry}
\usepackage[parfill]{parskip}
\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage{hyperref}
\frenchspacing
\author{Ariel Davis (azdavis), Jerry Yu (jerryy)}
\date{\today}
\title{15-418 Final Project Checkpoint 01}
\begin{document}
\maketitle

\section*{Progress Review}
We have finished the sequential implementation of our algorithm in Python.
(NumPy)
This includes both the segmentation and the blur.
We are currently working on the C implementation and brainstorming ways to use
CUDA for parallelism.

\begin{figure}[!htb]
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{farnam.jpg}
        \caption{Input Image}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{farnam_portrait.jpg}
        \caption{Output Portrait Mode Image}
    \end{minipage}\hfill
\end{figure}

Through implementing the algorithm, we have found that we had to make several
changes to our original design. For segmentation, we realized that using edges
and gradients with snakes was not giving us the results we wanted.
Much of the foreground was not captured by the snake and each point was
too far apart form a continuous mask for the foreground.

\begin{figure}[!htb]
    \begin{minipage}{0.30\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{farnam_edge.jpg}
        \caption{Edges Found}
    \end{minipage}\hfill
    \begin{minipage}{0.30\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{farnam_segmented.jpg}
        \caption{Snake Outline From Edges}
    \end{minipage}\hfill
    \begin{minipage}{0.30\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{farnam_segmented_rough.jpg}
        \caption{Snake Outline From Pixel Gradient}
    \end{minipage}\hfill
\end{figure}

So, we decided to revise our algorithm. We chose to implement a simplified
grab-cut algorithm.
\begin{enumerate}
    \item
        Designiate the borders of the image as the background.
    \item
        Get a color distribution of the background region. Group colors together
        based on a certain threshold.
    \item
        Filter colors that make up less than 1 percent of the background area.
    \item
        Create a foreground mask by finding every pixel with a color not
        in the background color distrubution.
    \item
        For every unmasked pixel, add it to the mask if two of its neighboring
        pixels were part of the mask.
    \item
        Blur all the pixels that are not within the foreground mask. (We have
        tried a box filter, gaussian filter, and bokeh filter and a large box
        gives us the best results)
    \item
        For each pixel in the mask, add the original pixel of the image into
        the blurred version of the image.
\end{enumerate}

\begin{figure}[!htb]
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{farnam_walls.jpg}
        \caption{Background Region (Step 1)}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{farnam_dude.jpg}
        \caption{Foreground Mask (Step 5)}
    \end{minipage}\hfill
\end{figure}

Most of the time in the last week was spent ironing out
the computer vision algorithm and trying to balance accuracy with
how generalizable the algorithm was. We tried many other methods like using
a background only image with a background / foreground image, but we finalized
what we have now moving foward.

\section*{Goals}
We took an additional 2 days to complete our goal of implementing the python
version, but we have completed it. We are confident we can finish the C
implementation by the end of the week. Once we optimize array patterns and
convolutions in C, we will start CUDA implementation. We are not sure of
the "nice to have" portrait mode on gifs or videos, but we will decide by the
next checkpoint.

\section*{Revised Schedule}

\begin{tabular}{l|l}
    Date & Item \\
    \hline
    2018-04-11 & Proposal \\
    2018-04-17 & Sequential Python: background detection and manipulation \\
    2018-04-20 & Sequential C: background detection and manipulation \\
    2018-04-23 & Parallel CUDA: background color distribution extraction \\
    2018-04-28 & Parallel CUDA: background mask \\
    2018-05-05 & Parallel CUDA: applying mask and blur \\
    2018-05-06 & Parallel CUDA: background manipulation \\
    2018-05-07 & Writeup and poster \\
    2018-05-08 & Presentation
\end{tabular}

\section*{Deliverables}
We will be able to implement the CUDA implemnetation of portrait mode.
We plan to show a gallery of before an examples for input image and output
portrait mode images. We are not sure of the exact speedup between the
CUDA implementation with the sequential C, but believe it will be significant
with the high number of iterations across every pixel with background
distribution and blur. We also plan on comparing the performance differences
between sequential python with CUDA and sequential C.

\section*{Issues}

\newpage

\section*{Sample Results Gallery}

\begin{figure}[!htb]
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{tiger.jpg}
        \caption{Input Image}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{tiger_portrait.jpg}
        \caption{Output Portrait Mode Image}
    \end{minipage}\hfill
\end{figure}
\begin{figure}[!htb]
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{elephant.jpg}
        \caption{Input Image}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{elephant_portrait.jpg}
        \caption{Output Portrait Mode Image}
    \end{minipage}\hfill
\end{figure}

\end{document}
