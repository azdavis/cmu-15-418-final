\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[letterpaper,margin=1in]{geometry}
\usepackage[parfill]{parskip}
\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage{hyperref}
\frenchspacing
\author{Ariel Davis (azdavis), Jerry Yu (jerryy)}
\date{\today}
\title{15-418 Final Project Checkpoint 02}
\begin{document}
\maketitle

\section{Progress Review}

We have finished both the sequential C implementation and parallel CUDA
implementation of our algorithm.

We have verified that all three implementations produce the same, bit-for-bit
results on a given input image.

In order to avoid any encode/decode steps when working with JPEG, we modified
the algorithm to work with PPM, which is an image format we used in Assignment
1 and is much easier to work with.

We saw a significant amount of speedup between the sequential Python and
sequential C implementations. Then, after completing the CUDA implementation,
we saw more impressive speedups. In the CUDA implementation, we took advantage
of shared memory for our blur convolutions and synchronized threads between
the load and blur steps.

\section{Preliminary Results}

Below, we have summarized some results. Although the speedup from Python to C
is also impressive, we do not explictly include it in the table below because
the focus of the project is to consider the speedup gained specifically by
utilizing parallelism, not by choosing a ``fast'' language. We have also emited
some python results because they take too long to run.

\begin{tabular}{l|l|l|l|l}
    Image (size in px) & Python & C & Cuda & Speedup \\
    \hline
    Elephant 389x584 & 2m39s & 2.84s & 0.345s & 8.23x \\
    Tiger 1400x845 & - & 18.1s & 0.328s & 55.19x \\
    Large Elephant 2594x3888 & - & 134.37s & 1.040s & 129.17x \\
\end{tabular}
\\
Time Breakdown in seconds for Large Elephant \\
\begin{tabular}{l|l|l|l}
    Task & C & Cuda & Speedup From Parallelism\\
    \hline
    Load Image & 0.5091 & 0.0132 & - \\
    CUDA Move Memory & - & 0.1734 & - \\
    Generate Mask & 0.1376 & 0.0963 & - \\
    Blur & 136.9151 & 0.2244 & 601.139x \\
    Write Image & 0.3073 & 0.4284 & -
\end{tabular}

Because of our time breakdown, we are spending the most time in writing the
image result, which cannot be parallelized. Also, we believe the overhead of
moving the memory into the GPU for generating the mask will take more time than
sequential, due to the CUDA Move Memory time. We will validate this soon.

\section{Goals}

We have essentially completed all the goals we set out to accomplish in our
proposal. However, we still have time left to work on the project.

We would like to try using OpenMP as a source of parallelism to achive speedup
in running our algorithm. We will revise the sequential C program to add OpenMP
pragmas, and compile sequential C and OpenMP-enabled C versions of the program
separately, as in Assignment 3.

We are interested as to what kinds of speedups we will see from sequential C to
OpenMP-enabled C. We expect there to be fairly significant speedups, but not on
the order of what we saw with CUDA, because our algorithm is basically various
image manipulations operations, and GPUs were originally designed to be able to
quickly execute such image manipulations.

We believe with the OpenMP approach of having less threads and less overhead of
moving data to a GPU, we can achieve more parallelism with the segmentation
part of our algorithm. However, most of the time is spent on blur, so this the
resulting speedup will not be as high.

Additionally, we are looking to implement the algorithm in ISPC if we have time.
If we have extra time, we can apply the algorithm to a video to show that is
able to run in live-time.

\section{Revised Schedule}

\begin{tabular}{l|l}
    Date & Item \\
    \hline
    2018-04-11 & Proposal \\
    2018-04-17 & Sequential Python: background detection and manipulation \\
    2018-04-20 & Sequential C: background detection and manipulation \\
    2018-04-23 & Parallel CUDA: background blur\\
    2018-04-25 & Parallel CUDA: optimizing with shared memory\\
    2018-04-27 & Parallel CUDA: final optimizations for Ariel and Jerry\\
    2018-04-29 & Parallel OMP: background detection and manipulation
                 for Ariel and Jerry\\
    2018-05-04 & Parallel ISPC: background detection and manipulation
                 for Ariel and Jerry\\
    2018-05-06 & Possibly Video for Ariel and Jerry\\
    2018-05-08 & Presentation
\end{tabular}

\section{Deliverables}

We have met our goal of implementing portrait mode in CUDA. We will likely be
able to implement the OMP and ISCP versions of the algorithm and compare the
results. It will be interesting to discuss how each framework's approach to
parallelism causes different speedup in different parts of the code. We have
been able to show 130x speedup with CUDA, but we anticipate OMP and ISPC to only
be able to achieve around 30x speedup due to GPUS having more computational
threads.

We plan to show a gallery of before an examples for input image and output
portrait mode images.

\section{Issues}

TODO
An issue with video is the speed of the parsing the frame may take longer than
the algorithm, but we will try to see if the computation can occur in live time.

\section{Sample Results Gallery}

TODO

\end{document}
